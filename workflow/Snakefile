# Snakefile
from snakemake.io import glob_wildcards


configfile: "config/config.yaml"
#configfile: "scripts/testing/config_test.yaml"
#configfile: "scripts/testing/regression_testing/config_BS_reg_test.yaml"


ROOT = config['dataset']["root_dir"]
DERIV = config['dataset']["derivatives_subfolder"]


def get_imagerecon_output():
    return (
        f"{ROOT}/derivatives/{DERIV}/image_results/"
        f"Xs_{{task}}"
        f"_cov_alpha_spatial_{config['image_recon']['alpha_spatial']}"
        f"_alpha_meas_{config['image_recon']['alpha_meas']}"
        + ("_direct" if config["image_recon"]["DIRECT"]["enable"] else "_indirect")
        + ("_Cmeas" if config["image_recon"]["Cmeas"]["enable"] else "_noCmeas")
        + ("_SB" if config["image_recon"]["spatial_basis"]["enable"] else "_noSB")
        + ".pkl.gz"
    )

def get_blockaverage_output():
    return (
        f"{ROOT}/derivatives/{DERIV}/blockaverage/sub-{{subject}}/sub-{{subject}}_task-{{task}}_nirs_blockaverage_{config['blockaverage']['rec_str']}.pkl"
    )
    
def get_groupaverage_output():
    return (
        f"{ROOT}/derivatives/{DERIV}/groupaverage/task-{{task}}_nirs_groupaverage_{config['blockaverage']['rec_str']}.pkl"
    )

rule all_default:
    input:
        expand(get_imagerecon_output(), task=config["dataset"]["task"])


rule all_preprocess:
    input:
        expand([
            (f"{ROOT}/derivatives/{DERIV}/preprocessed_data/sub-{{subject}}/sub-{{subject}}_task-{{task}}_run-{{run}}_nirs_preprocessed.pkl"),  #  preprocessed_dataessed snirf
            (f"{ROOT}/derivatives/{DERIV}/preprocessed_data/sub-{{subject}}/sub-{{subject}}_task-{{task}}_run-{{run}}_nirs_dataquality_geo.sidecar"), # data qual sidecar 
            ],
            subject = config["dataset"]["subject"],
            task = config["dataset"]["task"],
            run = config["dataset"]["run"]
            )
            
rule all_blockaverage:
    input:
        expand([
            #(f"{ROOT}/derivatives/{DERIV}/blockaverage/sub-{{subject}}/sub-{{subject}}_task-{{task}}_nirs_blockaverage.pkl"),  # blockaverage data
            get_blockaverage_output(),
            (f"{ROOT}/derivatives/{DERIV}/blockaverage/sub-{{subject}}/sub-{{subject}}_task-{{task}}_nirs_dataquality.json"),  # blockaverage dataqual
            (f"{ROOT}/derivatives/{DERIV}/blockaverage/sub-{{subject}}/sub-{{subject}}_task-{{task}}_nirs_geo.sidecar")
            ],
            subject = config["dataset"]["subject"],
            task = config["dataset"]["task"],
            run = config["dataset"]["run"]
            )      
                      
rule all_groupaverage:
    input:
        expand([  
            get_groupaverage_output(),
            #(f"{ROOT}/derivatives/{DERIV}/groupaverage/task-{{task}}_nirs_groupaverage.pkl") # groupaverage
            ],
            subject = config["dataset"]["subject"],
            task = config["dataset"]["task"],
            run = config["dataset"]["run"]
            )      
            
        

rule preprocess:
    input:
        # raw .snirf and events.tsv
        snirf = f"{ROOT}/sub-{{subject}}/nirs/sub-{{subject}}_task-{{task}}_run-{{run}}_nirs.snirf",
        events = f"{ROOT}/sub-{{subject}}/nirs/sub-{{subject}}_task-{{task}}_run-{{run}}_events.tsv",
        module1 = "scripts/modules/module_preprocess.py",
        module2 = "scripts/modules/module_plot_DQR.py"
    output:
        snirf = (f"{ROOT}/derivatives/{DERIV}/preprocessed_data/sub-{{subject}}/sub-{{subject}}_task-{{task}}_run-{{run}}_nirs_preprocessed.pkl"), # preprocessed snirf
        sidecar = (f"{ROOT}/derivatives/{DERIV}/preprocessed_data/sub-{{subject}}/sub-{{subject}}_task-{{task}}_run-{{run}}_nirs_dataquality_geo.sidecar"), # data qual sidecar
        
        # !!! figure out how to get these updated with each run of rule
        #dqr_plot = (f"{ROOT}/derivatives/{DERIV}/plots/DQR/sub-{{subject}}_task-{{task}}_run-{{run}}_nirs_DQR.png"),   # DQR plots
        #gvtd_plot = (f"{ROOT}/derivatives/{DERIV}/plots/DQR/gvtd/sub-{{subject}}_task-{{task}}_run-{{run}}_nirs_DQR_gvtd_hist.png"), # gvtd DQR plots
        #slope_plot = (f"{ROOT}/derivatives/{DERIV}/plots/DQR/slope/sub-{{subject}}_task-{{task}}_run-{{run}}_nirs_slope.png")  # slope DQR plots
    
    params:
        cfg_preprocess = config['preprocess'],
        cfg_dataset = config['dataset'],
        cfg_hrf = config['hrf'],
        mse_amp_thresh = config['groupaverage']['mse_amp_thresh']
    #log:
        #"logs/preprocess/sub-{subject}_task-{task}_run-{run}_nirs_preprocessed.log"   # empty bc have to use shell and not script
    script:
        "scripts/preprocess.py"



def all_preprocessed_runs(wc):
    ''' Return a list of all preprocessed .snirf files for this subject+task (i.e. all runs)'''  
    
    run_paths =  [
        f"{ROOT}/derivatives/{DERIV}/preprocessed_data/sub-{wc.subject}/"
        f"sub-{wc.subject}_task-{wc.task}_run-{run}_nirs_preprocessed.pkl"
        for run in config["dataset"]["run"]
    ]
    
    data_quality_paths = [
        f"{ROOT}/derivatives/{DERIV}/preprocessed_data/sub-{wc.subject}/"
        f"sub-{wc.subject}_task-{wc.task}_run-{run}_nirs_dataquality_geo.sidecar"
        for run in config["dataset"]["run"]
    ]
    
    return {
        "preproc":  run_paths,
        "quality":  data_quality_paths
    }
    
    

rule blockaverage:
    input:
        preproc  = lambda wc: all_preprocessed_runs(wc)["preproc"],
        quality  = lambda wc: all_preprocessed_runs(wc)["quality"]
        #all_preprocessed_runs   # list of all run files for curr sub and task 
    output:
        # block averaged data containing HRF for each task
        pickle = get_blockaverage_output(),
        #pickle = (f"{ROOT}/derivatives/{DERIV}/blockaverage/sub-{{subject}}/sub-{{subject}}_task-{{task}}_nirs_blockaverage.pkl"),
        json = (f"{ROOT}/derivatives/{DERIV}/blockaverage/sub-{{subject}}/sub-{{subject}}_task-{{task}}_nirs_dataquality.json"),
        geo = (f"{ROOT}/derivatives/{DERIV}/blockaverage/sub-{{subject}}/sub-{{subject}}_task-{{task}}_nirs_geo.sidecar")
    params:
        cfg_blockaverage = config['blockaverage'],
        cfg_dataset = config['dataset'],
        cfg_hrf = config['hrf']
    #log:
        #"logs/blockaverage/sub-{subject}_task-{task}_nirs_blockaverage.log"   # empty bc have to use shell and not script
    script:
        "scripts/blockaverage.py"
    #shell: r""" python "scripts/blockaverage.py" --in {input.preproc} --qc {input.quality} --out {output}"""
    
    

    
def all_blockaverage_files(wc):
    ''' Return a list of all blockaverage .pkl files for this subject+task (i.e. all subs)'''  
    
    blockavg_paths =  [
        f"{ROOT}/derivatives/{DERIV}/blockaverage/sub-{subject}/sub-{subject}_task-{wc.task}_nirs_blockaverage_{config['blockaverage']['rec_str']}.pkl"
        for subject in config["dataset"]["subject"]
    ]
    
    data_quality_paths = [
        f"{ROOT}/derivatives/{DERIV}/blockaverage/sub-{subject}/sub-{subject}_task-{wc.task}_nirs_dataquality.json"
        for subject in config["dataset"]["subject"]
    ]
    
    geo_paths = [
        f"{ROOT}/derivatives/{DERIV}/blockaverage/sub-{subject}/sub-{subject}_task-{wc.task}_nirs_geo.sidecar"
        for subject in config["dataset"]["subject"]
    ]
    
    #blockavg_nc_paths = [
     #   f"{ROOT}/derivatives/{DERIV}/blockaverage/sub-{subject}/sub-{subject}_task-{wc.task}_nirs_blockaverage.nc"
      #  for subject in config["dataset"]["subject"]
    #]
    
    #epoch_nc_paths = [
     #   f"{ROOT}/derivatives/{DERIV}/blockaverage/sub-{subject}/sub-{subject}_task-{wc.task}_nirs_epochs.nc"
     #   for subject in config["dataset"]["subject"]
    #]
    
    
    return {
        "blockavg":  blockavg_paths,
        "quality":  data_quality_paths, 
        "geo": geo_paths
        #"blockavg_nc": blockavg_nc_paths, 
        #"epochs_nc": epoch_nc_paths
    }
    


rule groupaverage:
    input: 
        blockavg_subs  = lambda wc: all_blockaverage_files(wc)["blockavg"], # block avg data
        quality  = lambda wc: all_blockaverage_files(wc)["quality"],    # quality metrics
        geo  = lambda wc: all_blockaverage_files(wc)["geo"]    # geometric pos and landmarks
        
        #blockavg_nc  = lambda wc: all_blockaverage_files(wc)["blockavg_nc"]    # blockaverage data net cdf
        #epochs_nc  = lambda wc: all_blockaverage_files(wc)["epochs_nc"]  # epochs data net cdf
    output:
        # group averaged data
        get_groupaverage_output()
        #(f"{ROOT}/derivatives/{DERIV}/groupaverage/task-{{task}}_nirs_groupaverage.pkl")   
    params:
        cfg_groupaverage = config["groupaverage"],
        cfg_dataset = config['dataset'],
        cfg_hrf = config['hrf'],
        cfg_blockaverage = config['blockaverage'],
        flag_prune_channels = config['preprocess']['steps']['prune']['enable'],
        mse_amp_thresh = config['preprocess']['steps']['prune']['amp_thresh']
    #run:
        #print(snakemake.input.blockavg_subs)
    script:
        "scripts/groupaverage.py"
        
        
# !!! store xarrays in netcdf file instead of pkl if snirf not enabled - similar to hdf file 
    # can store dataqual stuff to coordinate dim of xarray   



rule imagerecon:
    input:
        # group averaged data
        get_groupaverage_output()
        #(f"{ROOT}/derivatives/{DERIV}/groupaverage/task-{{task}}_nirs_groupaverage.pkl")    # - taking subject blockaverage and subj mse from dict
    output:
        get_imagerecon_output()
        #results = lambda wc: get_imagerecon_output(wc.task)
        #results = [get_imagerecon_output(c) for c in config["hrf"]["stim_lst"]] #expand(get_imagerecon_output, task=config["hrf"]["stim_lst"])
        
    params:
        cfg_img_recon = config['image_recon'],
        cfg_dataset = config['dataset'], 
        cfg_hrf = config['hrf']
    script:
        "scripts/image_recon.py"
        
        
