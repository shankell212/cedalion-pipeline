# Snakefile
from snakemake.io import glob_wildcards


configfile: "config/config.yaml"

ROOT = config['dataset']["root_dir"]
DERIV = config['dataset']["derivatives_subfolder"]

rule all:
    input:
        expand([
            #(f"{ROOT}/derivatives/{DERIV}/preprocessed_data/sub-{{subject}}/sub-{{subject}}_task-{{task}}_run-{{run}}_nirs_preprocessed.snirf"), # preprocessed_dataessed snirf
            #(f"{ROOT}/derivatives/{DERIV}/preprocessed_data/sub-{{subject}}/sub-{{subject}}_task-{{task}}_run-{{run}}_nirs_dataquality.json"), # preproc dataqual
            #(f"{ROOT}/derivatives/{DERIV}/blockaverage/sub-{{subject}}/sub-{{subject}}_task-{{task}}_nirs_blockaverage.pkl"),  # blockaverage data
            #(f"{ROOT}/derivatives/{DERIV}/blockaverage/sub-{{subject}}/sub-{{subject}}_task-{{task}}_nirs_dataquality.json"),  # blockaverage dataqual
            (f"{ROOT}/derivatives/{DERIV}/groupaverage/task-{{task}}_nirs_groupaverage.pkl") # groupaverage  
             
            ],
            subject = config["dataset"]["subject"],
            task = config["dataset"]["task"],
            run = config["dataset"]["run"]
            )
            
            # !!! only need to list final result file
        
        

rule preprocess:
    input:
        # raw .snirf and events.tsv
        snirf = f"{ROOT}/sub-{{subject}}/nirs/sub-{{subject}}_task-{{task}}_run-{{run}}_nirs.snirf",
        events = f"{ROOT}/sub-{{subject}}/nirs/sub-{{subject}}_task-{{task}}_run-{{run}}_events.tsv"
    output:
        snirf = (f"{ROOT}/derivatives/{DERIV}/preprocessed_data/sub-{{subject}}/sub-{{subject}}_task-{{task}}_run-{{run}}_nirs_preprocessed.snirf"), # preprocessed snirf
        sidecar = (f"{ROOT}/derivatives/{DERIV}/preprocessed_data/sub-{{subject}}/sub-{{subject}}_task-{{task}}_run-{{run}}_nirs_dataquality.json"), # data qual sidecar
        
        # !!! figure out how to get these updated with each run of rule
        #dqr_plot = (f"{ROOT}/derivatives/{DERIV}/plots/DQR/sub-{{subject}}_task-{{task}}_run-{{run}}_nirs_DQR.png"),   # DQR plots
        #gvtd_plot = (f"{ROOT}/derivatives/{DERIV}/plots/DQR/gvtd/sub-{{subject}}_task-{{task}}_run-{{run}}_nirs_DQR_gvtd_hist.png"), # gvtd DQR plots
        #slope_plot = (f"{ROOT}/derivatives/{DERIV}/plots/DQR/slope/sub-{{subject}}_task-{{task}}_run-{{run}}_nirs_slope.png")  # slope DQR plots

    
    params:
        cfg_preprocess = config['preprocess'],
        cfg_dataset = config['dataset'],
        
    #log:
        #"logs/preprocess/sub-{subject}_task-{task}_run-{run}_nirs_preprocessed.log"   # empty bc have to use shell and not script
    script:
        #"scripts/test.py"
        "scripts/preprocess.py"


def all_preprocessed_runs(wc):
    ''' Return a list of all preprocessed .snirf files for this subject+task (i.e. all runs)'''  
    
    run_paths =  [
        f"{ROOT}/derivatives/{DERIV}/preprocessed_data/sub-{wc.subject}/"
        f"sub-{wc.subject}_task-{wc.task}_run-{run}_nirs_preprocessed.snirf"
        for run in config["dataset"]["run"]
    ]
    
    data_quality_paths = [
        f"{ROOT}/derivatives/{DERIV}/preprocessed_data/sub-{wc.subject}/"
        f"sub-{wc.subject}_task-{wc.task}_run-{run}_nirs_dataquality.json"
        for run in config["dataset"]["run"]
    ]
    
    return {
        "preproc":  run_paths,
        "quality":  data_quality_paths
    }
    



rule blockaverage:
    input:
        preproc  = lambda wc: all_preprocessed_runs(wc)["preproc"],
        quality  = lambda wc: all_preprocessed_runs(wc)["quality"]
        #all_preprocessed_runs   # list of all run files for curr sub and task 
    output:
        # block averaged data containing HRF for each task
        pickle = (f"{ROOT}/derivatives/{DERIV}/blockaverage/sub-{{subject}}/sub-{{subject}}_task-{{task}}_nirs_blockaverage.pkl"),
        jason = (f"{ROOT}/derivatives/{DERIV}/blockaverage/sub-{{subject}}/sub-{{subject}}_task-{{task}}_nirs_dataquality.json"), 
        #bl_nc = (f"{ROOT}/derivatives/{DERIV}/blockaverage/sub-{{subject}}/sub-{{subject}}_task-{{task}}_nirs_blockaverage.nc"),
        #ep_nc = (f"{ROOT}/derivatives/{DERIV}/blockaverage/sub-{{subject}}/sub-{{subject}}_task-{{task}}_nirs_epochs.nc")
    params:
        cfg_blockaverage = config['blockaverage'],
        cfg_dataset = config['dataset'],
        cfg_hrf = config['hrf']
    #log:
        #"logs/blockaverage/sub-{subject}_task-{task}_nirs_blockaverage.log"   # empty bc have to use shell and not script
    script:
        "scripts/blockaverage.py"
    #shell: r""" python "scripts/blockaverage.py" --in {input.preproc} --qc {input.quality} --out {output}"""
    
    
    
    
def all_blockaverage_files(wc):
    ''' Return a list of all blockaverage .pkl files for this subject+task (i.e. all subs)'''  
    
    blockavg_paths =  [
        f"{ROOT}/derivatives/{DERIV}/blockaverage/sub-{subject}/sub-{subject}_task-{wc.task}_nirs_blockaverage.pkl"
        for subject in config["dataset"]["subject"]
    ]
    
    data_quality_paths = [
        f"{ROOT}/derivatives/{DERIV}/blockaverage/sub-{subject}/sub-{subject}_task-{wc.task}_nirs_dataquality.json"
        for subject in config["dataset"]["subject"]
    ]
    
    #blockavg_nc_paths = [
     #   f"{ROOT}/derivatives/{DERIV}/blockaverage/sub-{subject}/sub-{subject}_task-{wc.task}_nirs_blockaverage.nc"
      #  for subject in config["dataset"]["subject"]
    #]
    
    #epoch_nc_paths = [
     #   f"{ROOT}/derivatives/{DERIV}/blockaverage/sub-{subject}/sub-{subject}_task-{wc.task}_nirs_epochs.nc"
     #   for subject in config["dataset"]["subject"]
    #]
    
    
    return {
        "blockavg":  blockavg_paths,
        "quality":  data_quality_paths, 
        #"blockavg_nc": blockavg_nc_paths, 
        #"epochs_nc": epoch_nc_paths
    }
    
    
    



rule groupaverage:
    input: 
        blockavg_subs  = lambda wc: all_blockaverage_files(wc)["blockavg"], # block avg data
        quality  = lambda wc: all_blockaverage_files(wc)["quality"]    # quality metrics
        #blockavg_nc  = lambda wc: all_blockaverage_files(wc)["blockavg_nc"]    # blockaverage data net cdf
        #epochs_nc  = lambda wc: all_blockaverage_files(wc)["epochs_nc"]  # epochs data net cdf
    output:
        # group averaged data
        (f"{ROOT}/derivatives/{DERIV}/groupaverage/task-{{task}}_nirs_groupaverage.pkl")   
    params:
        cfg_groupaverage = config["groupaverage"],
        cfg_dataset = config['dataset'],
        cfg_hrf = config['hrf'],
        cfg_blockaverage = config['blockaverage'],
        flag_prune_channels = config['preprocess']['steps']['prune']['enable'],
        mse_amp_thresh = config['preprocess']['steps']['prune']['amp_thresh']
    #run:
        #print(snakemake.input.blockavg_subs)
    script:
        "scripts/groupaverage.py"
        
        
# !!! store xarrays in netcdf file instead of pkl if snirf not enabled - similar to hdf file 
    # can store dataqual stuff to coordinate dim of xarray   



# f'Xs_task_cov_alpha_spatial_{cfg_img_recon["alpha_spatial"]:.0e}_alpha_meas_{cfg_img_recon["alpha_meas"]:.0e}_{direct_name}_{Cmeas_name}_{SB_name}.pkl.gz'

        
        
